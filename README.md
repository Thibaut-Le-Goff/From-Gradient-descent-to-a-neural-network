<center><h2><ins>From Gradient-descent to a neural network</ins></h2></center>

This project is the rest of the previous one [here](https://github.com/Thibaut-Le-Goff/gradient-descent-for-Runst).

The goals of this project are:
- to see what the gradient descent algorithm may would look like if this was a neural network;
- to implement the algorithm to my main project, [here](https://github.com/Thibaut-Le-Goff/Runst).

<ins></ins>

<ins>hypothesis:</ins>
With respect to the sum in the neuron at layer N, we want to calculate what should be the $\textrm{\color{red}weight W1}$, the $\textrm{\color{blue}bias}$, and the sum the neuron at layer N - 1 receive (to create a loop):

<p align="center">
    <img src="images/hypothesis_layers_N_N-1.drawio.png" width="450"/>
</p>

